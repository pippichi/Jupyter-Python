{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用torchtext来创建vocabulary，然后把数据读成batch的格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import torch\n",
    "from torchtext.vocab import Vectors\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "random.seed(44)\n",
    "np.random.seed(44)\n",
    "torch.manual_seed(44)\n",
    "if USE_CUDA:\n",
    "    torch.cuda.manual_seed(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 #一个batch中有多少个句子（一列就是1个句子）\n",
    "EMBEDDING_SIZE = 100\n",
    "HIDDEN_SIZE = 100\n",
    "MAX_VOCAB_SIZE = 50000\n",
    "BPTT_LEN = 50 #RNN往回传的时候的词向量个数\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![QQ截图20200227131946.png](.\\image\\QQ截图20200227131946.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = torchtext.data.Field(lower=True)\n",
    "train,val,test = torchtext.datasets.LanguageModelingDataset.splits(path=\".\\data\",\n",
    "                                                 train=\"text8.train.txt\",\n",
    "                                                 test=\"text8.test.txt\",\n",
    "                                                 validation=\"text8.dev.txt\",\n",
    "                                                 text_field=TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这一步操作相当于Counter(text).most_common(SIZE)\n",
    "TEXT.build_vocab(train,max_size=MAX_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', 'the', 'of', 'and', 'one', 'in', 'a', 'to', 'zero']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![QQ截图20200227131245.png](.\\image\\QQ截图20200227131245.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1273"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.stoi.get(\"apple\") #apple这个词有1273个"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义一个iter，每个batch中有32个句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter,val_iter,test_iter = torchtext.data.BPTTIterator.splits((train,val,test),\n",
    "                                                                  batch_size=BATCH_SIZE,\n",
    "                                                                  device=device,\n",
    "                                                                  bptt_len=BPTT_LEN,\n",
    "                                                                   repeat=False,\n",
    "                                                                   shuffle=True\n",
    "                                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(train_iter)\n",
    "batch = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 32]\n",
      "\t[.text]:[torch.cuda.LongTensor of size 50x32 (GPU 0)]\n",
      "\t[.target]:[torch.cuda.LongTensor of size 50x32 (GPU 0)]\n",
      "tensor([[4815,   50,    6,  ..., 9116,   33,    7],\n",
      "        [3143, 2748,  495,  ...,  893,  277,  317],\n",
      "        [  13,    8,  850,  ...,  664,  824, 1602],\n",
      "        ...,\n",
      "        [   8,   34,  522,  ..., 5237,    3,   12],\n",
      "        [3628, 1266,  968,  ...,    3,    2,    6],\n",
      "        [   2,   54,   78,  ...,   12,  185, 3027]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(batch)\n",
    "print(batch.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anarchism originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans <unk> of the french revolution whilst the term is still used in a pejorative way to describe any act that used violent means to destroy the\n",
      "originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans <unk> of the french revolution whilst the term is still used in a pejorative way to describe any act that used violent means to destroy the organization\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(TEXT.vocab.itos[i] for i in batch.text[:,0].data.cpu()))\n",
    "print(\" \".join(TEXT.vocab.itos[i] for i in batch.target[:,0].data.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "organization of society it has also been taken up as a positive label by self defined anarchists the word anarchism is derived from the greek without archons ruler chief king anarchism as a political philosophy is the belief that rulers are unnecessary and should be abolished although there are differing\n",
      "\n",
      "of society it has also been taken up as a positive label by self defined anarchists the word anarchism is derived from the greek without archons ruler chief king anarchism as a political philosophy is the belief that rulers are unnecessary and should be abolished although there are differing interpretations\n",
      "1\n",
      "interpretations of what this means anarchism also refers to related social movements that advocate the elimination of authoritarian institutions particularly the state the word anarchy as most anarchists use it does not imply chaos nihilism or <unk> but rather a harmonious anti authoritarian society in place of what are regarded\n",
      "\n",
      "of what this means anarchism also refers to related social movements that advocate the elimination of authoritarian institutions particularly the state the word anarchy as most anarchists use it does not imply chaos nihilism or <unk> but rather a harmonious anti authoritarian society in place of what are regarded as\n",
      "2\n",
      "as authoritarian political structures and coercive economic institutions anarchists advocate social relations based upon voluntary association of autonomous individuals mutual aid and self governance while anarchism is most easily defined by what it is against anarchists also offer positive visions of what they believe to be a truly free society\n",
      "\n",
      "authoritarian political structures and coercive economic institutions anarchists advocate social relations based upon voluntary association of autonomous individuals mutual aid and self governance while anarchism is most easily defined by what it is against anarchists also offer positive visions of what they believe to be a truly free society however\n",
      "3\n",
      "however ideas about how an anarchist society might work vary considerably especially with respect to economics there is also disagreement about how a free society might be brought about origins and predecessors kropotkin and others argue that before recorded history human society was organized on anarchist principles most anthropologists follow\n",
      "\n",
      "ideas about how an anarchist society might work vary considerably especially with respect to economics there is also disagreement about how a free society might be brought about origins and predecessors kropotkin and others argue that before recorded history human society was organized on anarchist principles most anthropologists follow kropotkin\n",
      "4\n",
      "kropotkin and engels in believing that hunter gatherer bands were egalitarian and lacked division of labour accumulated wealth or decreed law and had equal access to resources william godwin anarchists including the the anarchy organisation and rothbard find anarchist attitudes in taoism from ancient china kropotkin found similar ideas in\n",
      "\n",
      "and engels in believing that hunter gatherer bands were egalitarian and lacked division of labour accumulated wealth or decreed law and had equal access to resources william godwin anarchists including the the anarchy organisation and rothbard find anarchist attitudes in taoism from ancient china kropotkin found similar ideas in stoic\n"
     ]
    }
   ],
   "source": [
    "for j in range(5):\n",
    "    batch = next(it)\n",
    "    print(j)\n",
    "    print(\" \".join(TEXT.vocab.itos[i] for i in batch.text[:,0].data.cpu()))\n",
    "    print()\n",
    "    print(\" \".join(TEXT.vocab.itos[i] for i in batch.target[:,0].data.cpu()))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![QQ截图20200227140704.png](.\\image\\QQ截图20200227140704.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self,vocab_size,embed_size,hidden_size):\n",
    "        super(LSTMModel,self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size,embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size,hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size,vocab_size)\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "    def forward(self,text,hidden):\n",
    "        #forward pass\n",
    "        #text: seq_length * batch_size\n",
    "        emb = self.embed(text)# seq_size * batch_size * embed_size\n",
    "        output,hidden = self.lstm(emb,hidden)\n",
    "        #具体的看pytorch官网\n",
    "        #output: seq_length * batch_size * hidden_size\n",
    "        #hidden: (1*batch_size*hidden_size,1*batch_size*hidden)\n",
    "        #output = # (seq_length * batch_size) *hidden_size\n",
    "        out_vocab = self.linear(output.view(-1,output.shape[2])) #(seq_length * batch_size) * vocab_size\n",
    "        out_vocab = out_vocab.view(output.size(0),output.size(1),out_vocab.size(-1))\n",
    "        return out_vocab,hidden\n",
    "    def init_hidden(self,bsz,requires_grad=True):\n",
    "        #以下是技巧写法，不是固定的\n",
    "        weight = next(self.parameters())\n",
    "        return (weight.new_zeros((1,bsz,self.hidden_size),requires_grad=True),\n",
    "               weight.new_zeros((1,bsz,self.hidden_size),requires_grad=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![QQ截图20200227142001.png](.\\image\\QQ截图20200227142001.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(vocab_size=len(TEXT.vocab),\n",
    "                 embed_size=EMBEDDING_SIZE,\n",
    "                 hidden_size=HIDDEN_SIZE)\n",
    "if USE_CUDA:\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.5862,  1.1253,  1.8306,  ..., -0.4256, -0.5353, -0.5766],\n",
       "        [ 1.9729,  0.1628, -0.5393,  ..., -0.8279, -1.1062, -0.5235],\n",
       "        [ 1.4656,  0.6486,  1.0052,  ..., -0.3202, -1.2253, -1.3718],\n",
       "        ...,\n",
       "        [-0.2977,  1.0607,  0.1781,  ..., -1.1225, -0.6912,  0.0626],\n",
       "        [-1.0276, -0.1802,  1.7577,  ...,  0.2666, -1.6965,  0.7423],\n",
       "        [-0.3957,  0.6342,  0.0749,  ..., -2.2819,  0.9556,  0.9199]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![QQ截图20200227152348.png](.\\image\\QQ截图20200227152348.png)\n",
    "我们需要定义下面的一个function，帮助我们把一个hidden state和计算图之前的历史分离"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![QQ截图20200227152529.png](.\\image\\QQ截图20200227152529.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repackage_hidden(h):\n",
    "    if isinstance(h,torch.Tensor):\n",
    "        #h这个虽然看起来是个Tensor，但实际上是个结点，与之前的结点是有联系的，\n",
    "        #这里将h分离开来成为一个全新的结点以避免将前面所有的历史节点数据都一起训练导致内存爆表\n",
    "        return h.detach()\n",
    "    else:\n",
    "        #提前知道了还可能出现的类型是tuple\n",
    "        return tuple(repackage_hidden(v) for v in h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "#将learning_rate自动调低\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer,0.5) #0.5表示lr降一半"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,data):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    total_count = 0.\n",
    "    it = iter(data)\n",
    "    with torch.no_grad():\n",
    "        hidden = model.init_hidden(BATCH_SIZE,requires_grad=False)\n",
    "        for i,batch in enumerate(it):\n",
    "            data,target = batch.text,batch.target\n",
    "            hidden = repackage_hidden(hidden)\n",
    "            output,hidden = model(data,hidden)\n",
    "        \n",
    "            loss = loss_fn(output.view(-1,VOCAB_SIZE),target.view(-1))\n",
    "            total_loss = loss.item() * np.multiply(*data.size())#data.size() is a tuple\n",
    "            total_count = np.multiply(*data.size())\n",
    "    loss = total_loss / total_count\n",
    "    model.train()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 iteration 0 loss 10.82917594909668\n",
      "save to lm.pth\n",
      "epoch 0 iteration 100 loss 7.412539005279541\n",
      "epoch 0 iteration 200 loss 7.053678512573242\n",
      "epoch 0 iteration 300 loss 7.3103928565979\n",
      "epoch 0 iteration 400 loss 7.003200054168701\n",
      "epoch 0 iteration 500 loss 6.818564414978027\n",
      "epoch 0 iteration 600 loss 6.732349395751953\n",
      "epoch 0 iteration 700 loss 6.72703742980957\n",
      "epoch 0 iteration 800 loss 6.524006366729736\n",
      "epoch 0 iteration 900 loss 6.771305561065674\n",
      "epoch 0 iteration 1000 loss 6.825018405914307\n",
      "epoch 0 iteration 1100 loss 6.512195587158203\n",
      "epoch 0 iteration 1200 loss 6.399179458618164\n",
      "epoch 0 iteration 1300 loss 6.504211902618408\n",
      "epoch 0 iteration 1400 loss 6.193819046020508\n",
      "epoch 0 iteration 1500 loss 6.32082462310791\n",
      "epoch 0 iteration 1600 loss 6.163266181945801\n",
      "epoch 0 iteration 1700 loss 6.407052993774414\n",
      "epoch 0 iteration 1800 loss 6.464570999145508\n",
      "epoch 0 iteration 1900 loss 6.444336414337158\n",
      "epoch 0 iteration 2000 loss 6.4136881828308105\n",
      "epoch 0 iteration 2100 loss 6.38249397277832\n",
      "epoch 0 iteration 2200 loss 6.32967472076416\n",
      "epoch 0 iteration 2300 loss 6.264688491821289\n",
      "epoch 0 iteration 2400 loss 6.287586688995361\n",
      "epoch 0 iteration 2500 loss 6.3842854499816895\n",
      "epoch 0 iteration 2600 loss 6.38232421875\n",
      "epoch 0 iteration 2700 loss 5.933348178863525\n",
      "epoch 0 iteration 2800 loss 6.338284969329834\n",
      "epoch 0 iteration 2900 loss 6.145878314971924\n",
      "epoch 0 iteration 3000 loss 6.332238674163818\n",
      "epoch 0 iteration 3100 loss 6.318630218505859\n",
      "epoch 0 iteration 3200 loss 6.245954513549805\n",
      "epoch 0 iteration 3300 loss 6.211572647094727\n",
      "epoch 0 iteration 3400 loss 6.073106288909912\n",
      "epoch 0 iteration 3500 loss 6.260738372802734\n",
      "epoch 0 iteration 3600 loss 6.152454376220703\n",
      "epoch 0 iteration 3700 loss 5.948307991027832\n",
      "epoch 0 iteration 3800 loss 5.989022731781006\n",
      "epoch 0 iteration 3900 loss 6.0636138916015625\n",
      "epoch 0 iteration 4000 loss 6.057612895965576\n",
      "epoch 0 iteration 4100 loss 6.092159271240234\n",
      "epoch 0 iteration 4200 loss 6.056032180786133\n",
      "epoch 0 iteration 4300 loss 6.0646185874938965\n",
      "epoch 0 iteration 4400 loss 5.970338821411133\n",
      "epoch 0 iteration 4500 loss 5.930389404296875\n",
      "epoch 0 iteration 4600 loss 5.955753326416016\n",
      "epoch 0 iteration 4700 loss 6.324640274047852\n",
      "epoch 0 iteration 4800 loss 6.0462260246276855\n",
      "epoch 0 iteration 4900 loss 5.788254261016846\n",
      "epoch 0 iteration 5000 loss 5.8600945472717285\n",
      "epoch 0 iteration 5100 loss 5.868405342102051\n",
      "epoch 0 iteration 5200 loss 6.071737289428711\n",
      "epoch 0 iteration 5300 loss 6.106188774108887\n",
      "epoch 0 iteration 5400 loss 5.761327743530273\n",
      "epoch 0 iteration 5500 loss 6.014504909515381\n",
      "epoch 0 iteration 5600 loss 5.912165641784668\n",
      "epoch 0 iteration 5700 loss 5.9182634353637695\n",
      "epoch 0 iteration 5800 loss 5.861190319061279\n",
      "epoch 0 iteration 5900 loss 6.089907646179199\n",
      "epoch 0 iteration 6000 loss 5.8826823234558105\n",
      "epoch 0 iteration 6100 loss 5.8875555992126465\n",
      "epoch 0 iteration 6200 loss 5.967533588409424\n",
      "epoch 0 iteration 6300 loss 5.955418109893799\n",
      "epoch 0 iteration 6400 loss 5.878255844116211\n",
      "epoch 0 iteration 6500 loss 5.708099365234375\n",
      "epoch 0 iteration 6600 loss 6.036111831665039\n",
      "epoch 0 iteration 6700 loss 5.781749725341797\n",
      "epoch 0 iteration 6800 loss 5.811840057373047\n",
      "epoch 0 iteration 6900 loss 6.06484317779541\n",
      "epoch 0 iteration 7000 loss 5.827232837677002\n",
      "epoch 0 iteration 7100 loss 5.8126912117004395\n",
      "epoch 0 iteration 7200 loss 5.928573131561279\n",
      "epoch 0 iteration 7300 loss 5.842893123626709\n",
      "epoch 0 iteration 7400 loss 5.914267063140869\n",
      "epoch 0 iteration 7500 loss 5.715020656585693\n",
      "epoch 0 iteration 7600 loss 5.735927581787109\n",
      "epoch 0 iteration 7700 loss 5.887493133544922\n",
      "epoch 0 iteration 7800 loss 5.827922821044922\n",
      "epoch 0 iteration 7900 loss 5.89063835144043\n",
      "epoch 0 iteration 8000 loss 5.802704334259033\n",
      "epoch 0 iteration 8100 loss 5.830994129180908\n",
      "epoch 0 iteration 8200 loss 5.598951816558838\n",
      "epoch 0 iteration 8300 loss 5.516168117523193\n",
      "epoch 0 iteration 8400 loss 5.955944061279297\n",
      "epoch 0 iteration 8500 loss 5.78409481048584\n",
      "epoch 0 iteration 8600 loss 5.8135504722595215\n",
      "epoch 0 iteration 8700 loss 5.697015762329102\n",
      "epoch 0 iteration 8800 loss 5.702731132507324\n",
      "epoch 0 iteration 8900 loss 6.083580493927002\n",
      "epoch 0 iteration 9000 loss 5.710195541381836\n",
      "epoch 0 iteration 9100 loss 5.790273666381836\n",
      "epoch 0 iteration 9200 loss 5.538788318634033\n",
      "epoch 0 iteration 9300 loss 5.553201675415039\n",
      "epoch 0 iteration 9400 loss 5.589569091796875\n",
      "epoch 0 iteration 9500 loss 5.9320068359375\n",
      "save to lm.pth\n",
      "epoch 1 iteration 0 loss 5.939969539642334\n",
      "save to lm.pth\n",
      "epoch 1 iteration 100 loss 5.840826034545898\n",
      "epoch 1 iteration 200 loss 5.6893463134765625\n",
      "epoch 1 iteration 300 loss 6.100806713104248\n",
      "epoch 1 iteration 400 loss 5.800473690032959\n",
      "epoch 1 iteration 500 loss 5.6559038162231445\n",
      "epoch 1 iteration 600 loss 5.632571220397949\n",
      "epoch 1 iteration 700 loss 5.626739978790283\n",
      "epoch 1 iteration 800 loss 5.580440521240234\n",
      "epoch 1 iteration 900 loss 5.78129768371582\n",
      "epoch 1 iteration 1000 loss 5.711545944213867\n",
      "epoch 1 iteration 1100 loss 5.6449151039123535\n",
      "epoch 1 iteration 1200 loss 5.440712928771973\n",
      "epoch 1 iteration 1300 loss 5.6411638259887695\n",
      "epoch 1 iteration 1400 loss 5.306860446929932\n",
      "epoch 1 iteration 1500 loss 5.535159111022949\n",
      "epoch 1 iteration 1600 loss 5.366478443145752\n",
      "epoch 1 iteration 1700 loss 5.5618486404418945\n",
      "epoch 1 iteration 1800 loss 5.794867992401123\n",
      "epoch 1 iteration 1900 loss 5.617300510406494\n",
      "epoch 1 iteration 2000 loss 5.778303623199463\n",
      "epoch 1 iteration 2100 loss 5.707215785980225\n",
      "epoch 1 iteration 2200 loss 5.704232215881348\n",
      "epoch 1 iteration 2300 loss 5.6322221755981445\n",
      "epoch 1 iteration 2400 loss 5.591487407684326\n",
      "epoch 1 iteration 2500 loss 5.733631610870361\n",
      "epoch 1 iteration 2600 loss 5.735533237457275\n",
      "epoch 1 iteration 2700 loss 5.304476737976074\n",
      "epoch 1 iteration 2800 loss 5.773862838745117\n",
      "epoch 1 iteration 2900 loss 5.5666632652282715\n",
      "epoch 1 iteration 3000 loss 5.757775783538818\n",
      "epoch 1 iteration 3100 loss 5.743075370788574\n",
      "epoch 1 iteration 3200 loss 5.731076717376709\n",
      "epoch 1 iteration 3300 loss 5.635670185089111\n",
      "epoch 1 iteration 3400 loss 5.532938003540039\n",
      "epoch 1 iteration 3500 loss 5.710498809814453\n",
      "epoch 1 iteration 3600 loss 5.652681827545166\n",
      "epoch 1 iteration 3700 loss 5.388953685760498\n",
      "epoch 1 iteration 3800 loss 5.450162887573242\n",
      "epoch 1 iteration 3900 loss 5.485105514526367\n",
      "epoch 1 iteration 4000 loss 5.508392333984375\n",
      "epoch 1 iteration 4100 loss 5.6169233322143555\n",
      "epoch 1 iteration 4200 loss 5.59373664855957\n",
      "epoch 1 iteration 4300 loss 5.558701992034912\n",
      "epoch 1 iteration 4400 loss 5.474461078643799\n",
      "epoch 1 iteration 4500 loss 5.434810638427734\n",
      "epoch 1 iteration 4600 loss 5.523135185241699\n",
      "epoch 1 iteration 4700 loss 5.78422737121582\n",
      "epoch 1 iteration 4800 loss 5.6593017578125\n",
      "epoch 1 iteration 4900 loss 5.362751483917236\n",
      "epoch 1 iteration 5000 loss 5.373041152954102\n",
      "epoch 1 iteration 5100 loss 5.384819507598877\n",
      "epoch 1 iteration 5200 loss 5.632867336273193\n",
      "epoch 1 iteration 5300 loss 5.737313747406006\n",
      "epoch 1 iteration 5400 loss 5.301611423492432\n",
      "epoch 1 iteration 5500 loss 5.604869365692139\n",
      "epoch 1 iteration 5600 loss 5.394530773162842\n",
      "epoch 1 iteration 5700 loss 5.53720235824585\n",
      "epoch 1 iteration 5800 loss 5.47523307800293\n",
      "epoch 1 iteration 5900 loss 5.723918914794922\n",
      "epoch 1 iteration 6000 loss 5.493467807769775\n",
      "epoch 1 iteration 6100 loss 5.48414421081543\n",
      "epoch 1 iteration 6200 loss 5.60177755355835\n",
      "epoch 1 iteration 6300 loss 5.601229190826416\n",
      "epoch 1 iteration 6400 loss 5.481052875518799\n",
      "epoch 1 iteration 6500 loss 5.312691688537598\n",
      "epoch 1 iteration 6600 loss 5.616121768951416\n",
      "epoch 1 iteration 6700 loss 5.410728931427002\n",
      "epoch 1 iteration 6800 loss 5.423140048980713\n",
      "epoch 1 iteration 6900 loss 5.661586761474609\n",
      "epoch 1 iteration 7000 loss 5.478388786315918\n",
      "epoch 1 iteration 7100 loss 5.39613151550293\n",
      "epoch 1 iteration 7200 loss 5.568835258483887\n",
      "epoch 1 iteration 7300 loss 5.481339931488037\n",
      "epoch 1 iteration 7400 loss 5.509588718414307\n",
      "epoch 1 iteration 7500 loss 5.327098369598389\n",
      "epoch 1 iteration 7600 loss 5.396482467651367\n",
      "epoch 1 iteration 7700 loss 5.538879871368408\n",
      "epoch 1 iteration 7800 loss 5.509750843048096\n",
      "epoch 1 iteration 7900 loss 5.531849384307861\n",
      "epoch 1 iteration 8000 loss 5.4810099601745605\n",
      "epoch 1 iteration 8100 loss 5.479935169219971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 iteration 8200 loss 5.2688751220703125\n",
      "epoch 1 iteration 8300 loss 5.1887431144714355\n",
      "epoch 1 iteration 8400 loss 5.69419002532959\n",
      "epoch 1 iteration 8500 loss 5.4859418869018555\n",
      "epoch 1 iteration 8600 loss 5.482663154602051\n",
      "epoch 1 iteration 8700 loss 5.378697395324707\n",
      "epoch 1 iteration 8800 loss 5.379619121551514\n",
      "epoch 1 iteration 8900 loss 5.718132972717285\n",
      "epoch 1 iteration 9000 loss 5.391956806182861\n",
      "epoch 1 iteration 9100 loss 5.498380184173584\n",
      "epoch 1 iteration 9200 loss 5.2552995681762695\n",
      "epoch 1 iteration 9300 loss 5.188258171081543\n",
      "epoch 1 iteration 9400 loss 5.246530055999756\n",
      "epoch 1 iteration 9500 loss 5.611937046051025\n",
      "save to lm.pth\n"
     ]
    }
   ],
   "source": [
    "# NUM_EPOCHS = 2\n",
    "# GRAD_CLIP = 5.0 #将所有参数梯度控制在5.0以下\n",
    "\n",
    "# val_losses = []\n",
    "# for epoch in range(NUM_EPOCHS):\n",
    "#     model.train()\n",
    "#     it = iter(train_iter)\n",
    "#     hidden = model.init_hidden(BATCH_SIZE)\n",
    "#     for i,batch in enumerate(it):\n",
    "#         data,target = batch.text,batch.target\n",
    "#         hidden = repackage_hidden(hidden)\n",
    "#         output,hidden = model(data,hidden) #bacpropgate through all the iteration\n",
    "        \n",
    "#         loss = loss_fn(output.view(-1,VOCAB_SIZE),target.view(-1))#batch_size*target_class_dim*batch_size\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "        \n",
    "#         #将所有参数梯度控制在5.0以下\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(),GRAD_CLIP)\n",
    "        \n",
    "#         optimizer.step()\n",
    "#         if i % 100 == 0:\n",
    "#             print(\"epoch\",epoch,\"iteration\",i,\"loss\",loss.item())\n",
    "            \n",
    "#         #存模型\n",
    "#         if i % 9500 == 0:\n",
    "#             val_loss = evaluate(model,val_iter)\n",
    "#             if len(val_losses)==0 or val_loss < min(val_losses):\n",
    "#                 torch.save(model.state_dict(),\"lm.pth\")\n",
    "#                 print(\"save to lm.pth\")\n",
    "#             else:\n",
    "#                 # learning rate decay\n",
    "#                 scheduler.step()\n",
    "#             val_losses.append(val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下操作相当于将batch_text_size()这个元组里的元素拆开之后再相乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "672"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(*batch.text.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将模型load回来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Field' object has no attribute 'vocab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-38ca4102441b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m best_model = LSTMModel(vocab_size=len(TEXT.vocab),\n\u001b[0m\u001b[0;32m      2\u001b[0m                  \u001b[0membed_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEMBEDDING_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                  hidden_size=HIDDEN_SIZE)\n\u001b[0;32m      4\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mUSE_CUDA\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Field' object has no attribute 'vocab'"
     ]
    }
   ],
   "source": [
    "best_model = LSTMModel(vocab_size=len(TEXT.vocab),\n",
    "                 embed_size=EMBEDDING_SIZE,\n",
    "                 hidden_size=HIDDEN_SIZE)\n",
    "if USE_CUDA:\n",
    "    best_model = best_model.to(device)\n",
    "best_model.load_state_dict(torch.load(\"lm.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![QQ截图20200227164812.png](.\\image\\QQ截图20200227164812.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![QQ截图20200227165000.png](.\\image\\QQ截图20200227165000.png)\n",
    "![QQ截图20200228141648.png](.\\image\\QQ截图20200228141648.png)\n",
    "### multinomial表示logits越大该词被sampling的概率越大，也可以将它改为argmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![QQ截图20200228143548.png](.\\image\\QQ截图20200228143548.png)\n",
    "![QQ截图20200228144055.png](.\\image\\QQ截图20200228144055.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field()\n",
    "# TEXT = data.Field(tokenize='spacy')\n",
    "LABEL = data.LabelField(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![QQ截图20200228221206.png](.\\image\\QQ截图20200228221206.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchtext import datasets\n",
    "train_data,test_data = datasets.IMDB.splits(TEXT,LABEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看每个数据split有多少条数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples:0\n",
      "Number of testing examples:0\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples:{len(train_data)}')\n",
    "print(f'Number of testing examples:{len(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看一个example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-f0def5e87e37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![QQ截图20200228223514.png](.\\image\\QQ截图20200228223514.png)\n",
    "![QQ截图20200228223553.png](.\\image\\QQ截图20200228223553.png)\n",
    "![QQ截图20200228224248.png](.\\image\\QQ截图20200228224248.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-1d5e8be65922>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSEED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "import random\n",
    "train_data,valid_data = train_data.split(random_state=random.seed(SEED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查一下现在每个部分有多少条数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples:0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'valid_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-c5e03982c183>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Number of training examples:{len(train_data)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Number of validation examples:{len(valid_data)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Number of testing examples:{len(test_data)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'valid_data' is not defined"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples:{len(train_data)}')\n",
    "print(f'Number of validation examples:{len(valid_data)}')\n",
    "print(f'Number of testing examples:{len(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![QQ截图20200228224506.png](.\\image\\QQ截图20200228224506.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████▉| 399999/400000 [00:16<00:00, 24964.05it/s]\n"
     ]
    }
   ],
   "source": [
    "#TEXT.build_vocab(train_data,max_size=25000)\n",
    "#LABEL.build_vocab(train_data)\n",
    "TEXT.build_vocab(train_data,max_size=25000,vectors=\"glove.6B.100d\",unk_init=torch.Tensor.normal_)#这里的glove是预训练的自向量，这里把它带进来可以使其训练的速度要快很多\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary:2\n",
      "Unique tokens in LABEL vocabulary:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary:{len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in LABEL vocabulary:{len(LABEL.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![QQ截图20200228224926.png](.\\image\\QQ截图20200228224926.png)\n",
    "![QQ截图20200228225223.png](.\\image\\QQ截图20200228225223.png)\n",
    "![QQ截图20200228225253.png](.\\image\\QQ截图20200228225253.png)\n",
    "![QQ截图20200228225315.png](.\\image\\QQ截图20200228225315.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置批次大小\n",
    "BATCH_SIZE=64\n",
    "#判断使用cpu还是gpu进行模型训练\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#句子迭代器的生成，其中BucetIterator表示将长度差不多的词语放在一起\n",
    "train_iterator,valid_iterator,test_iterator = data.BucketIterator.splits( \n",
    "    (train_data,valid_data,test_data),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device)\n",
    "#seq_len * batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(valid_iterator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![QQ截图20200229193455.png](.\\image\\QQ截图20200229193455.png)\n",
    "![QQ截图20200229193939.png](.\\image\\QQ截图20200229193939.png)\n",
    "![QQ截图20200229195200.png](.\\image\\QQ截图20200229195200.png)\n",
    "![QQ截图20200229195306.png](.\\image\\QQ截图20200229195306.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "\n",
    "class WordAVGModel(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_size,output_size,pad_idx):\n",
    "        super(WordAVGModel,self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size,embedding_size,padding_idx=pad_idx)#这里的pad_idx是指当模型遇到某个index的时候输出padding向量，实际上padding向量就是一个0向量\n",
    "        self.linear = nn.Linear(embedding_size,output_size)\n",
    "        \n",
    "    def forward(self,text):\n",
    "        embedded = self.embed(text) #[seq_len,batch_size,embedding_size]\n",
    "#         embeded = embeded.transpose(1,0) #[batch_size,seq_len,embedding_size]\n",
    "        #或者：\n",
    "        embedded = embedded.permute(1,0,2) #[batch_size,seq_len,embedding_size]\n",
    "        pooled = F.avg_pool2d(embedded,(embedded.shape[1],1)).squeeze() #avg_pool2d的第二个参数中的第一个参数表示将其压扁成embedded.shape[1]的大小，第二个参数表示不去动他。此时shape会变成[batch_size,1,embedding_size],要将这个1去掉我们用squeeze()\n",
    "        return self.linear(pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(TEXT.vocab)\n",
    "EMBEDDING_SIZE = 100\n",
    "OUTPUT_SIZE = 1\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = WordAVGModel(vocab_size=VOCAB_SIZE,\n",
    "                    embedding_size=EMBEDDING_SIZE,\n",
    "                    output_size=OUTPUT_SIZE,\n",
    "                    pad_idx=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000301"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)#numel() is the sum of basic parameters\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000200"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![QQ截图20200229212405.png](.\\image\\QQ截图20200229212405.png)\n",
    "这里加入了词向量glove（斯坦福训练的优质词向量）之后模型的收敛会快很多"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_embedding = TEXT.vocab.vectors #这个embedding是被glove初始化的embedding\n",
    "\n",
    "UNK_IDX = TEXT.vocab.stoi(TEXT.unk_token)\n",
    "#.copy_()带“_”的方法都是inplace的方法，会将原数据替换掉\n",
    "model.embed.weight.data.copy_(pretrained_embedding)\n",
    "model.embed.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_SIZE)\n",
    "model.embed.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型\n",
    "计算预测的准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer =torch.optim.Adam(model.parameters())\n",
    "crit = nn.BCEWithLogitsLoss() #the expression is a binary cross entropy, \"logits\" means output data has not been sigmoid,if data has been sigmoid, we call it \"probability\"  rather \"logits\"\n",
    "\n",
    "model = model.to(device)\n",
    "crit = crit.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算准确率\n",
    "def binary_accuracy(preds,y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,iterator,optimizer,crit):\n",
    "    epoch_loss,epoch_acc,total_len = 0.,0.,0.\n",
    "    model.train()\n",
    "    for batch in iterator:\n",
    "        preds = model(batch.text).squeeze()#因为模型默认size为[batch_size ,1]所以需要squeeze()\n",
    "        loss = crit(preds,batch.label)\n",
    "        acc = binary_accuracy(preds,batch.label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item() * len(batch.label)\n",
    "        epoch_acc += acc.item() * len(batch.label)        \n",
    "        total_len += len(batch.label)\n",
    "        \n",
    "    return epoch_loss / total_len,epoch_acc / total_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate does not need optimizer\n",
    "def evaluate(model,iterator,crit):\n",
    "    epoch_loss,epoch_acc,total_len = 0.,0.,0.\n",
    "    epoch_loss,epoch_acc = 0.,0.\n",
    "    model.eval()\n",
    "    for batch in iterator:\n",
    "        preds = model(batch.text).squeeze()#因为模型默认size为[batch_size ,1]所以需要squeeze()\n",
    "        loss = crit(preds,batch.label)\n",
    "        acc = binary_accuracy(preds,batch.label)\n",
    "        \n",
    "        epoch_loss += loss.item() * len(batch.label)\n",
    "        epoch_acc += acc.item() * len(batch.label)\n",
    "        total_len += len(batch.label)\n",
    "    model.train()\n",
    "        \n",
    "    return epoch_loss / total_len, epoch_acc / total_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 10\n",
    "best_valid_acc = 0.\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss,train_acc = train(model,train_iterator,optimizer,crit)\n",
    "    valid_loss,valid_acc = evaluate(model,valid_iterator,crit)\n",
    "    \n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        torch.save(model.state_dict(),\"wordavg-model.pth\")\n",
    "    print(\"Epoch\",epoch,\"Train Loss\",train_loss,\"Train Acc\",train_acc)\n",
    "    print(\"Epoch\",epoch,\"Valid Loss\",valid_loss,\"Valid Acc\",valid_acc)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "slp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![QQ截图20200301143004.png](.\\image\\QQ截图20200301143004.png)\n",
    "![QQ截图20200301143153.png](.\\image\\QQ截图20200301143153.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    #初始化\n",
    "    def __init__(self,vocab_size,embedding_size,output_size,pad_idx,hidden_size,dropout):\n",
    "        super(LSTMModel,self).__init__()\n",
    "        #嵌入层\n",
    "        self.embed = nn.Embedding(vocab_size,embedding_size,padding_idx=pad_idx)\n",
    "        #参数bidirectional是指此同时训练两个lstm，一个正向一个负向\n",
    "        self.lstm = nn.LSTM(embedding_size,hidden_size,num_layers=2,bidirectional=True)\n",
    "        #线性层\n",
    "        self.linear = nn.Linear(hidden_size,output_size)\n",
    "        #dropout：随机将一些信息丢弃，防止模型过拟合\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self,text):\n",
    "        #[seq_len,batch_size,embedding_size]\n",
    "        embedded = self.embed(text) \n",
    "        embedded = self.dropout(embedded)\n",
    "        #这里hidden不传的话会默认传入全零的向量\n",
    "        output,(hidden,cell) = self.lstm(embedded)\n",
    "        \n",
    "        #hidden:[2 * batch_size * hidden_size]\n",
    "        hidden = torch.cat([hidden[-1],hidden[-2]],dim=1)\n",
    "        #squeeze():将hidden层值全为1的无用维度删去\n",
    "        hidden = self.dropout(hidden.squeeze())\n",
    "        \n",
    "        return self.linear(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel(vocab_size=VOCAB_SIZE,\n",
    "                 embedding_size=EMBEDDING_SIZE,\n",
    "                 output_size=OUTPUT_SIZE,\n",
    "                 pad_idx=PAD_IDX,\n",
    "                 hidden_size=HIDDEN_SIZE,\n",
    "                 dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data,max_size=25000,vectors=\"glove.6B.100d\",unk_init=torch.Tensor.normal_)#这里的glove是预训练的自向量，这里把它带进来可以使其训练的速度要快很多\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "pretrained_embedding = TEXT.vocab.vectors\n",
    "model.embed.weight.data.copy_(pretrained_embedding)\n",
    "\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "model.embed.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_SIZE)\n",
    "model.embed.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer =torch.optim.Adam(model.parameters())\n",
    "crit = nn.BCEWithLogitsLoss() #the expression is a binary cross entropy, \"logits\" means output data has not been sigmoid,if data has been sigmoid, we call it \"probability\"  rather \"logits\"\n",
    "\n",
    "model = model.to(device)\n",
    "crit = crit.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCH = 10\n",
    "best_valid_acc = 0.\n",
    "for epoch in range(N_EPOCH):\n",
    "    train_loss,train_acc = train(model,train_iterator,optimizer,crit)\n",
    "    valid_loss,valid_acc = evaluate(model,valid_iterator,crit)\n",
    "    \n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        torch.save(model.state_dict(),\"lstm-model.pth\")\n",
    "    print(\"Epoch\",epoch,\"Train Loss\",train_loss,\"Train Acc\",train_acc)\n",
    "    print(\"Epoch\",epoch,\"Valid Loss\",valid_loss,\"Valid Acc\",valid_acc)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT_DIM = len(TEXT.vocab) #输入层大小\n",
    "# EMBEDDING_DIM = 100 #词嵌入层大小\n",
    "# HIDDEN_DIM = 256 #隐藏层大小\n",
    "# OUTPUT_DIM = 1 #输出层大小\n",
    "# N_LAYERS = 2 #隐藏层叠加层数\n",
    "# BIDIRECTIONAL = True #设置双向LSTM\n",
    "# DROPOUT = 0.5 #设置信息保留百分比，防止过拟合\n",
    "# PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token] #长度过短单词转换成对应下标\n",
    "\n",
    "# model = LSTM(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, \n",
    "#             N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX) #模型的初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_embeddings = TEXT.vocab.vectors #未经过训练的原始词向量\n",
    "# model.embedding.weight.data.copy_(pretrained_embeddings) #模型词嵌入层初始化\n",
    "# UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token] #低频词语转换成对应下标\n",
    "\n",
    "# #模型词嵌入层低频单词词向量初始化\n",
    "# model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM) \n",
    "# #模型词嵌入层长度过短单词词向量初始化\n",
    "# model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#句子输入接口\n",
    "def predict_sentiment(sentence):\n",
    "    #将句子进行分割\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    #使用stoi函数将文本转化成建立的词数统计字典中对应的下标值\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    #将该下标值数组变为张量\n",
    "    tensor = torch.LongTensor(indexed)\n",
    "    #为该张量第一个维度上创建一个全是数字1的维度，此时它的大小将变为[len(tensor),2]\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    #对模型进行预测，并使用sigmoid函数将模型的输出值转变到可控的数值范围内\n",
    "    prediction = torch.sigmoid(model(tensor))\n",
    "    #返回预测的概率\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Loss:0.337 | Test Acc: 86.73%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![QQ截图20200301161515.png](.\\image\\QQ截图20200301161515.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_size,output_size,pad_idx,dropout,num_filters,filter_size):\n",
    "        super(CNN,self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size,embedding_size,padding_idx=pad_idx)\n",
    "        self.conv = nn.Conv2d(in_channels=1,out_channels=num_filters,kernel_size=(filter_size,embedding_size))\n",
    "        self.linear = nn.Linear(num_filters,output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self,text):\n",
    "        text = text.permute(1,0) #[batch_size,seq_len]\n",
    "        embedded = self.embed(text)#[batch_size,seq_len,embedding_size]\n",
    "        embedded = embedded.unsqueeze(1)#[batch_size,1,seq_len,embedding_size]\n",
    "        conved = F.relu(self.conv(embedded))#[batch_size,num_filters,seq_len-filter_size+1,1]\n",
    "        conved = conved.squeeze(3)#[batch_size,num_filters,seq_len-filter_size+1]\n",
    "        # max over time pooling\n",
    "        pooled = F.max_pooled(conved,conved.shape[2])#[batch_size,num_filters,1]\n",
    "        pooled = pooled.squeeze(2)\n",
    "        pooled = self.dropout(pooled)\n",
    "        \n",
    "        return self.linear(pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#改进并联多个convd\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_size,output_size,pad_idx,dropout,num_filters,filter_sizes):\n",
    "        super(CNN,self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size,embedding_size,padding_idx=pad_idx)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=1,out_channels=num_filters,\n",
    "                     kernel_size=(fs,embedding_size))\n",
    "            for fs in filter_sizes\n",
    "        ]) # 3个CNN\n",
    "#         self.conv = nn.Conv2d(in_channels=1,out_channels=num_filters,kernel_size=(filter_size,embedding_size))\n",
    "        self.linear = nn.Linear(embedding_size,output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self,text):\n",
    "        text = text.permute(1,0) #[batch_size,seq_len]\n",
    "        embedded = self.embed(text)#[batch_size,seq_len,embedding_size]\n",
    "        embedded = embedded.unsqueeze(1)#[batch_size,1,seq_len,embedding_size]\n",
    "#         conved = F.relu(self.conv(embedded))#[batch_size,num_filters,seq_len-filter_size+1,1]\n",
    "#         conved = conved.squeeze(3)#[batch_size,num_filters,seq_len-filter_size+1]\n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "        # max over time pooling\n",
    "#         pooled = F.max_pooled(conved,conved.shape[2])#[batch_size,num_filters,1]\n",
    "#         pooled = pooled.squeeze(2)\n",
    "        pooled = [F.max_pooled(conv,conv.shape[2]) for conv in conved]\n",
    "        pooled = torch.cat(pooled,dim=1) #batch_size,3*num_filters\n",
    "        pooled = self.dropout(pooled)\n",
    "        \n",
    "        return self.linear(pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(vocab_size=VOCAB_SIZE,\n",
    "           embedding_size=EMBEDDING_SIZE,\n",
    "           output_size=OUTPUT_SIZE,\n",
    "           pad_idx=PAD_IDX,\n",
    "           num_filters=100,\n",
    "           filter_sizes=[3,4,5],\n",
    "           dropout=0.5)\n",
    "\n",
    "pretrained_embedding = TEXT.vocab.vectors\n",
    "model.embed.weight.data.copy_(pretrained_embedding)\n",
    "\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "model.embed.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_SIZE)\n",
    "model.embed.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_SIZE)\n",
    "\n",
    "optimizer =torch.optim.Adam(model.parameters())\n",
    "crit = nn.BCEWithLogitsLoss() #the expression is a binary cross entropy, \"logits\" means output data has not been sigmoid,if data has been sigmoid, we call it \"probability\"  rather \"logits\"\n",
    "\n",
    "model = model.to(device)\n",
    "crit = crit.to(device)\n",
    "\n",
    "N_EPOCH = 10\n",
    "best_valid_acc = 0.\n",
    "for epoch in range(N_EPOCH):\n",
    "    train_loss,train_acc = train(model,train_iterator,optimizer,crit)\n",
    "    valid_loss,valid_acc = evaluate(model,valid_iterator,crit)\n",
    "    \n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        torch.save(model.state_dict(),\"cnn-model.pth\")\n",
    "    print(\"Epoch\",epoch,\"Train Loss\",train_loss,\"Train Acc\",train_acc)\n",
    "    print(\"Epoch\",epoch,\"Valid Loss\",valid_loss,\"Valid Acc\",valid_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hierarchicalLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"cnn-model.pth\"))\n",
    "test_loss,test_acc = evaluate(model,test_iterator,crit)\n",
    "print(\"cnn model test loss: \",test_loss,\"accuracy: \"test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['it', 'is', 'brilliant'], 'label': 'pos'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'text': ['it','is','brilliant'],'label':'pos'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'It is brilliant', 'label': 'pos'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'text': 'It is brilliant','label':'pos'}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
