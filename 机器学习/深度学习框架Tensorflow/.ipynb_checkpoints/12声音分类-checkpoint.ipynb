{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# 数据集：https://serv.cusp.nyu.edu/projects/urbansounddataset/  \n",
    "# \n",
    "# librosa：https://github.com/librosa/librosa  \n",
    "# \n",
    "# 分类：  \n",
    "# 0 = air_conditioner  \n",
    "# 1 = car_horn  \n",
    "# 2 = children_playing  \n",
    "# 3 = dog_bark  \n",
    "# 4 = drilling  \n",
    "# 5 = engine_idling  \n",
    "# 6 = gun_shot  \n",
    "# 7 = jackhammer  \n",
    "# 8 = siren  \n",
    "# 9 = street_music  \n",
    "\n",
    "# In[1]:\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import librosa # pip install librosa\n",
    "from tqdm import tqdm # pip install tqdm\n",
    "import random\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "# Parameters\n",
    "# ==================================================\n",
    "\n",
    "# Data loading params\n",
    "# validation数据集占比\n",
    "tf.flags.DEFINE_float(\"dev_sample_percentage\", .2, \"Percentage of the training data to use for validation\")\n",
    "# 父目录\n",
    "tf.flags.DEFINE_string(\"parent_dir\", \"audio/\", \"Data source for the data.\")\n",
    "# 子目录\n",
    "tf.flags.DEFINE_string(\"tr_sub_dirs\", ['fold1/','fold2/','fold3/'], \"Data source for the data.\")\n",
    "\n",
    "# Model Hyperparameters\n",
    "# 第一层输入，MFCC信号\n",
    "tf.flags.DEFINE_integer(\"n_inputs\", 40, \"Number of MFCCs (default: 40)\")\n",
    "# cell个数\n",
    "tf.flags.DEFINE_string(\"n_hidden\", 300, \"Number of cells (default: 300)\")\n",
    "# 分类数\n",
    "tf.flags.DEFINE_integer(\"n_classes\", 10, \"Number of classes (default: 10)\")\n",
    "# 学习率\n",
    "tf.flags.DEFINE_integer(\"lr\", 0.005, \"Learning rate (default: 0.005)\")\n",
    "# dropout参数\n",
    "tf.flags.DEFINE_float(\"dropout_keep_prob\", 0.5, \"Dropout keep probability (default: 0.5)\")\n",
    "\n",
    "# Training parameters\n",
    "# 批次大小\n",
    "tf.flags.DEFINE_integer(\"batch_size\", 50, \"Batch Size (default: 50)\")\n",
    "# 迭代周期\n",
    "tf.flags.DEFINE_integer(\"num_epochs\", 100, \"Number of training epochs (default: 100)\")\n",
    "# 多少step测试一次\n",
    "tf.flags.DEFINE_integer(\"evaluate_every\", 50, \"Evaluate model on dev set after this many steps (default: 50)\")\n",
    "# 多少step保存一次模型\n",
    "tf.flags.DEFINE_integer(\"checkpoint_every\", 500, \"Save model after this many steps (default: 500)\")\n",
    "# 最多保存多少个模型\n",
    "tf.flags.DEFINE_integer(\"num_checkpoints\", 2, \"Number of checkpoints to store (default: 2)\")\n",
    "\n",
    "# flags解析\n",
    "FLAGS = tf.flags.FLAGS\n",
    "FLAGS._parse_flags()\n",
    "\n",
    "# 打印所有参数\n",
    "print(\"\\nParameters:\")\n",
    "for attr, value in sorted(FLAGS.__flags.items()):\n",
    "    print(\"{}={}\".format(attr.upper(), value))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "# 获得训练用的wav文件路径列表  \n",
    "def get_wav_files(parent_dir,sub_dirs): \n",
    "    wav_files = []  \n",
    "    for l, sub_dir in enumerate(sub_dirs):\n",
    "        wav_path = os.path.join(parent_dir, sub_dir)\n",
    "        for (dirpath, dirnames, filenames) in os.walk(wav_path):  \n",
    "            for filename in filenames:  \n",
    "                if filename.endswith('.wav') or filename.endswith('.WAV'):  \n",
    "                    filename_path = os.sep.join([dirpath, filename])  \n",
    "                    wav_files.append(filename_path)  \n",
    "    return wav_files  \n",
    "\n",
    "# 获取文件mfcc特征和对应标签\n",
    "def extract_features(wav_files):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    for wav_file in tqdm(wav_files):\n",
    "        # 读入音频文件\n",
    "        audio,fs = librosa.load(wav_file)\n",
    "\n",
    "        # 获取音频mfcc特征\n",
    "        # [n_steps, n_inputs]\n",
    "        mfccs = np.transpose(librosa.feature.mfcc(y=audio, sr=fs, n_mfcc=FLAGS.n_inputs), [1,0]) \n",
    "        inputs.append(mfccs.tolist()) \n",
    "    #获取label\n",
    "    for wav_file in wav_files:\n",
    "        label = wav_file.split('/')[-1].split('-')[1]\n",
    "        labels.append(label) \n",
    "    return inputs, np.array(labels, dtype=np.int)\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "# 获得训练用的wav文件路径列表 \n",
    "wav_files = get_wav_files(FLAGS.parent_dir,FLAGS.tr_sub_dirs)\n",
    "# 获取文件mfcc特征和对应标签\n",
    "tr_features,tr_labels = extract_features(wav_files)\n",
    "\n",
    "np.save('tr_features.npy',tr_features)\n",
    "np.save('tr_labels.npy',tr_labels)\n",
    "\n",
    "# tr_features=np.load('tr_features.npy')\n",
    "# tr_labels=np.load('tr_labels.npy')\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "#(batch,step,input)\n",
    "#(50,173,40)\n",
    "\n",
    "# 计算最长的step\n",
    "wav_max_len = max([len(feature) for feature in tr_features])\n",
    "print(\"max_len:\",wav_max_len)\n",
    "\n",
    "# 填充0\n",
    "tr_data = []\n",
    "for mfccs in tr_features:  \n",
    "    while len(mfccs) < wav_max_len: #只要小于wav_max_len就补n_inputs个0\n",
    "        mfccs.append([0] * FLAGS.n_inputs) \n",
    "    tr_data.append(mfccs)\n",
    "\n",
    "tr_data = np.array(tr_data)\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "# Randomly shuffle data\n",
    "np.random.seed(10)\n",
    "shuffle_indices = np.random.permutation(np.arange(len(tr_data)))\n",
    "x_shuffled = tr_data[shuffle_indices]\n",
    "y_shuffled = tr_labels[shuffle_indices]\n",
    "\n",
    "# Split train/test set\n",
    "# TODO: This is very crude, should use cross-validation\n",
    "# 数据集切分为两部分\n",
    "dev_sample_index = -1 * int(FLAGS.dev_sample_percentage * float(len(y_shuffled)))\n",
    "train_x, test_x = x_shuffled[:dev_sample_index], x_shuffled[dev_sample_index:]\n",
    "train_y, test_y = y_shuffled[:dev_sample_index], y_shuffled[dev_sample_index:]\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "# placeholder\n",
    "x = tf.placeholder(\"float\", [None, wav_max_len, FLAGS.n_inputs])\n",
    "y = tf.placeholder(\"float\", [None])\n",
    "dropout = tf.placeholder(tf.float32)\n",
    "# learning rate\n",
    "lr = tf.Variable(FLAGS.lr, dtype=tf.float32, trainable=False)\n",
    "\n",
    "# 定义RNN网络\n",
    "# 初始化权制和偏置\n",
    "weights = tf.Variable(tf.truncated_normal([FLAGS.n_hidden, FLAGS.n_classes], stddev=0.1))\n",
    "biases = tf.Variable(tf.constant(0.1, shape=[FLAGS.n_classes]))\n",
    "\n",
    "# 多层网络\n",
    "num_layers = 3\n",
    "def grucell():\n",
    "    cell = tf.contrib.rnn.GRUCell(FLAGS.n_hidden)\n",
    "#     cell = tf.contrib.rnn.LSTMCell(FLAGS.n_hidden)\n",
    "    cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=dropout)\n",
    "    return cell\n",
    "cell = tf.contrib.rnn.MultiRNNCell([grucell() for _ in range(num_layers)])\n",
    "\n",
    "\n",
    "outputs,final_state = tf.nn.dynamic_rnn(cell,x,dtype=tf.float32)\n",
    "\n",
    "# 预测值\n",
    "prediction = tf.nn.softmax(tf.matmul(final_state[0],weights) + biases)\n",
    "\n",
    "# labels转one_hot格式\n",
    "one_hot_labels = tf.one_hot(indices=tf.cast(y, tf.int32), depth=FLAGS.n_classes)\n",
    "\n",
    "# loss\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=one_hot_labels))\n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(cross_entropy)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(prediction,1), tf.argmax(one_hot_labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "def batch_iter(data, batch_size, num_epochs, shuffle=True):\n",
    "    \"\"\"\n",
    "        Generates a batch iterator for a dataset.\n",
    "    \"\"\"\n",
    "    data = np.array(data)\n",
    "    data_size = len(data)\n",
    "    # 每个epoch的num_batch\n",
    "    num_batches_per_epoch = int((len(data) - 1) / batch_size) + 1\n",
    "    print(\"num_batches_per_epoch:\",num_batches_per_epoch)\n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle the data at each epoch\n",
    "        if shuffle:\n",
    "            shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "            shuffled_data = data[shuffle_indices]\n",
    "        else:\n",
    "            shuffled_data = data\n",
    "        for batch_num in range(num_batches_per_epoch):\n",
    "            start_index = batch_num * batch_size\n",
    "            end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "            yield shuffled_data[start_index:end_index]\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "# 定义saver\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init) \n",
    "\n",
    "    # Generate batches\n",
    "    batches = batch_iter(list(zip(train_x, train_y)), FLAGS.batch_size, FLAGS.num_epochs)\n",
    "\n",
    "    for i,batch in enumerate(batches):\n",
    "        i = i + 1\n",
    "        x_batch, y_batch = zip(*batch)\n",
    "        sess.run([optimizer], feed_dict={x: x_batch, y: y_batch, dropout: FLAGS.dropout_keep_prob})\n",
    "        \n",
    "        # 测试\n",
    "        if i % FLAGS.evaluate_every == 0:\n",
    "            sess.run(tf.assign(lr, FLAGS.lr * (0.99 ** (i // FLAGS.evaluate_every))))\n",
    "            learning_rate = sess.run(lr)\n",
    "            tr_acc, _loss = sess.run([accuracy, cross_entropy], feed_dict={x: train_x, y: train_y, dropout: 1.0})\n",
    "            ts_acc = sess.run(accuracy, feed_dict={x: test_x, y: test_y, dropout: 1.0})\n",
    "            print(\"Iter {}, loss {:.5f}, tr_acc {:.5f}, ts_acc {:.5f}, lr {:.5f}\".format(i, _loss, tr_acc, ts_acc, learning_rate))\n",
    "\n",
    "        # 保存模型\n",
    "        if i % FLAGS.checkpoint_every == 0:\n",
    "            path = saver.save(sess, \"sounds_models/model\", global_step=i)\n",
    "            print(\"Saved model checkpoint to {}\\n\".format(path))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
